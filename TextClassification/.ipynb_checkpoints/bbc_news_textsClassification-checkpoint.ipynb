{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a893cb5b",
   "metadata": {},
   "source": [
    "# Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b66723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "## nltk\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87a3fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "file_path = './bbc/'\n",
    "# load_files()\n",
    "bbc_data = load_files(file_path, encoding='utf-8', decode_error='replace')\n",
    "type(bbc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a975cd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.ipynb_checkpoints': 1, 'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
     ]
    }
   ],
   "source": [
    "# sanity check of data\n",
    "for labels, count in bbc_data.items():\n",
    "    labels, count = np.unique(bbc_data.target, return_counts=True)\n",
    "    label_names = np.array(bbc_data.target_names)[labels]\n",
    "    \n",
    "# display count (frequency) per category\n",
    "print(dict(zip(label_names, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85dd4b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Howard dismisses Tory tax fears\\n\\nMichael How...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gritty return for Prince of Persia\\n\\nStill ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philippoussis doubt over Open bid\\n\\nMark Phil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horror film heads US box office\\n\\nA low-budge...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coach Ranieri sacked by Valencia\\n\\nClaudio Ra...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  labels\n",
       "0  Howard dismisses Tory tax fears\\n\\nMichael How...       3\n",
       "1  Gritty return for Prince of Persia\\n\\nStill ba...       5\n",
       "2  Philippoussis doubt over Open bid\\n\\nMark Phil...       4\n",
       "3  Horror film heads US box office\\n\\nA low-budge...       2\n",
       "4  Coach Ranieri sacked by Valencia\\n\\nClaudio Ra...       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into pandas dataframe\n",
    "bbc_df = pd.DataFrame({'sentence':bbc_data.data,\n",
    "                       'labels': bbc_data.target})\n",
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cfff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2226, 2)\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "print(bbc_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903d974",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "    - remove special characters\n",
    "    - remove single character\n",
    "    - removing single character from start\n",
    "    - converting multiple spaces into single space\n",
    "    - removing prefix\n",
    "    - texts into lower cases\n",
    "    - stopwords - 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82533a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love hatred none', 'change world', 'every element fresh begining']\n"
     ]
    }
   ],
   "source": [
    "# define function for text processing\n",
    "def texts_processing(data):\n",
    "    \"\"\"\n",
    "    Function to process the sentence such as special characters,\n",
    "    single character, prefixes, leading character.\n",
    "    \n",
    "    Parameters: texts (not as String).\n",
    "    Return: Cleanned texts for Text Classification. \n",
    "    \"\"\"\n",
    "    # empty list to store the processed texts\n",
    "    corpus_list = list()\n",
    "    # try with excpetion of TypeError\n",
    "    try:\n",
    "        # iterate over the texts in each row\n",
    "        for texts in range(0, len(data)):\n",
    "            # remove special characters\n",
    "            text = re.sub(r'\\W', ' ', data['sentence'][texts])\n",
    "            # remove single character\n",
    "            text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "            # removing single character from start \n",
    "            text = re.sub(r'^[a-zA-Z]\\s+', ' ', text)\n",
    "            # multiple spaces into single spaces\n",
    "            text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "            # removing prefixes\n",
    "            text = re.sub(r'^b\\s+', '', text)\n",
    "            # into lower case\n",
    "            text = text.lower()\n",
    "            # split into lists\n",
    "            text = text.split()\n",
    "            # WordNet\n",
    "            stemmer = WordNetLemmatizer()\n",
    "            text = [stemmer.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "            # join text\n",
    "            text = ' '.join(text)\n",
    "            # append the list\n",
    "            corpus_list.append(text)\n",
    "    except TypeError:\n",
    "        print(\"TypeError: list indices must be integers or slices, not string \")\n",
    "        \n",
    "    return corpus_list\n",
    "\n",
    "# sanity check - calling function on raw data with some of well known quotes\n",
    "raw_data = pd.DataFrame({'sentence':[\"Love For All, Hatred For None.\",\n",
    "                                  \"Change the world by being yourself.\",\n",
    "                                  \"Every element is the fresh begining.\"], \n",
    "                         'labels': [0, 1, 2]})\n",
    "raw_data\n",
    "# calling the function\n",
    "\n",
    "corpus = texts_processing(raw_data)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc12b8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['howard dismisses tory tax fear michael howard dismissed fear conservative plan 4bn tax cut modest defended package saying plan tory first budget hoped able go tory monday highlighted 35bn wasteful spending would stop allow tax cut reduced borrowing spending key service labour liberal democrat say party sum add claim would cut frontline service tory tax plan follows complaint party mp mr howard shadow chancellor oliver letwin taken long unveil proposal promised figure yet reveal tax would targeted tory backbencher edward leigh said proposal step right direction told financial time would come sooner much greater tax cut interviewed bbc radio 2 jeremy vine show mr howard said perfectly true attacked one side people think ought promising much much bigger tax cut spending cut side people say able achieve tax cut think got right mr howard said voter faced clear choice next election waste tax labour tory value money lower tax added would like able time sure able start got recognise limit one go first budget got responsible latest tory plan came campaigning election widely expected may gathered pace liberal democrat launched pre election platform leader charles kennedy saying party authentic opposition particularly iraq war council tax university tuition fee lib dem treasury spokesman vince cable also branded tory plan fantasy economics labour hit back tory proposal even publication election coordinator alan milburn accusing mr howard producing fraudulent prospectus party tuesday challenged tory publish full report david james trouble shooter asked identify possible saving tory turn demanding tony blair spell tax would raise win election', 'gritty return prince persia still basking relatively recent glory last year sand time dashing prince persia back warrior within bellicose mood last time sequel give franchise grim gritty new look ramp action violence control super athletic prince third person perspective time travelling plot hinge dahaka consuming monster pursuing hero age way dispel turn back clock kill sultry empress time ever creates sand time caused great beast creation studiously structured though back story everything boil old fashioned fantasy gameplay prof whole dependable need ever since series groundbreaking beginning commodore amiga prince persia always meticulously animated acrobatic move provide energetic blend leaping preposterously piece scenery lopping enemy body part flashy move back full evidence tremendous fun perform perfect combining speed best fun although getting handle take practice plenty skill reach point haphazard business often perform stunning triple somersault pirouette wall knock three enemy one glorious swoop plummeting purposefully cliff doom turn mean getting set back annoyingly long distance save fountain dotted along path expected fiendish puzzle present correct combat really stepped game developer combined acrobatic flair gruesome slaying technique wonderfully imaginative way slicing foe middle one particularly entertaining method seeing warrior within slick package game intro movie phenomenally good actually ultimate disservice game commences par jaw dropping opening sequence onimusha 3 earlier year game begin something anti climax said graphic excellent indeed among striking satisfying element game music probably worst aspect merit free heavy metal soundtrack swiftly want turn something strangely unsatisfying game perhaps precisely graphic mechanic good story overall experience quite engaging somehow add le sum part technically impressive outright enjoyable say warrior within anything superb adventure thoroughly enjoy quite take character new height might hoped']\n"
     ]
    }
   ],
   "source": [
    "# caling function bbc_df\n",
    "bbc_corpus = texts_processing(bbc_df)\n",
    "print(bbc_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8dbd15",
   "metadata": {},
   "source": [
    "# Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a333a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968290e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf279c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
